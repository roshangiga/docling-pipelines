{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docling Pipelines: All use-cases + Combined flow\n",
    "\n",
    "This notebook lets you run every script in `scripts/` with a brief explanation, and also run a one-pass combined pipeline (Picture Description + Formula Enrichment + Contextual Hybrid Chunking).\n",
    "\n",
    "Inputs go in `source/`. Outputs are written to `output/`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Ensure dependencies (safe to re-run)\n",
    "!pip install -q -r requirements.txt"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pathlib import Path\n",
    "\n",
    "project_root = Path().resolve()\n",
    "src_dir = project_root / 'source'\n",
    "out_dir = project_root / 'output'\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('Project root:', project_root)\n",
    "print('Source dir:', src_dir)\n",
    "print('Output dir:', out_dir)\n",
    "print('Source files:', list(src_dir.glob('*')))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) general_convert.py\n",
    "Converts PDFs or URLs into Markdown and JSON using Docling's basic conversion.\n",
    "- Input: files in `source/` (e.g., PDFs) or URLs (edit the script if needed).\n",
    "- Output: `.md` and `.json` under `output/`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%run scripts/general_convert.py"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) vlm_image_understanding.py\n",
    "Uses the VLM pipeline (SmolDocling) to better understand image-heavy PDFs (figures, charts).\n",
    "- Input: image-heavy PDFs in `source/`.\n",
    "- Output: `.md` in `output/` (with enhanced figure understanding)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%run scripts/vlm_image_understanding.py"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) maths_processing.py\n",
    "Converts documents then extracts math snippets/equations heuristically.\n",
    "- Input: math-containing files in `source/` (e.g., MD or PDF).\n",
    "- Output: Markdown and extracted math artifacts in `output/`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%run scripts/maths_processing.py"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) contextual_hybrid_chunking.py\n",
    "Creates chunks using `HybridChunker` and computes a context-enriched string for each chunk.\n",
    "- Input: `.md`, `.pdf`, `.docx`, `.html` in `source/`.\n",
    "- Output: `.txt` and `.jsonl` with raw and enriched chunk text in `output/`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%run scripts/contextual_hybrid_chunking.py"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) enrich_formula_understanding.py\n",
    "Enables Formula Understanding (`PdfPipelineOptions.do_formula_enrichment = True`).\n",
    "- Adds LaTeX extraction and improved formula rendering (MathML in HTML export).\n",
    "- Input: PDFs in `source/`.\n",
    "- Output: `.md` and `.html` in `output/`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%run scripts/enrich_formula_understanding.py"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) enrich_picture_description.py\n",
    "Enables Picture Description (`PdfPipelineOptions.do_picture_description = True`) to caption figures and images.\n",
    "- Optionally select VLM presets in the script (e.g., SmolVLM or Granite).\n",
    "- Input: PDFs in `source/`.\n",
    "- Output: `.md` in `output/`."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%run scripts/enrich_picture_description.py"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) One-pass combination: picture description + formula enrichment + contextual chunking\n",
    "This cell performs both enrichments in the converter, then passes the resulting document to `HybridChunker` and writes raw + contextualized chunks."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from datetime import datetime\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.chunking import HybridChunker\n",
    "\n",
    "# Find a PDF in source/\n",
    "pdf_path = next((p for p in src_dir.glob('*.pdf')), None)\n",
    "assert pdf_path is not None, 'Put a PDF into source/'\n",
    "\n",
    "# Enable both enrichments in the pipeline\n",
    "pipe = PdfPipelineOptions()\n",
    "pipe.do_picture_description = True\n",
    "pipe.do_formula_enrichment = True\n",
    "\n",
    "converter = DocumentConverter(\n",
    "    format_options={InputFormat.PDF: PdfFormatOption(pipeline_options=pipe)}\n",
    ")\n",
    "\n",
    "dl_doc = converter.convert(str(pdf_path)).document\n",
    "\n",
    "# Chunk and contextualize\n",
    "chunker = HybridChunker()\n",
    "chunks = list(chunker.chunk(dl_doc=dl_doc))\n",
    "\n",
    "ts = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "base = f'{pdf_path.stem}__combo__{ts}'\n",
    "txt_path = out_dir / f'{base}.txt'\n",
    "jsonl_path = out_dir / f'{base}.jsonl'\n",
    "\n",
    "import json\n",
    "with txt_path.open('w', encoding='utf-8') as f_txt, jsonl_path.open('w', encoding='utf-8') as f_jsonl:\n",
    "    for i, ch in enumerate(chunks):\n",
    "        raw = ch.text or ''\n",
    "        enriched = chunker.contextualize(chunk=ch)\n",
    "        # Write TXT\n",
    "        f_txt.write(f'=== {i} ===\\n')\n",
    "        f_txt.write('-- raw --\\n')\n",
    "        f_txt.write(raw + '\\n')\n",
    "        f_txt.write('-- enriched --\\n')\n",
    "        f_txt.write(enriched + '\\n\\n')\n",
    "        # Write JSONL\n",
    "        f_jsonl.write(json.dumps({\n",
    "            'index': i,\n",
    "            'raw': raw,\n",
    "            'enriched': enriched,\n",
    "            'path': getattr(ch, 'path', None),\n",
    "            'id': getattr(ch, 'id', None),\n",
    "        }, ensure_ascii=False) + '\\n')\n",
    "\n",
    "print('Wrote:', txt_path)\n",
    "print('Wrote:', jsonl_path)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Inspect outputs"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "for p in sorted(out_dir.glob('*')):\n",
    "    print(p.name)"
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
