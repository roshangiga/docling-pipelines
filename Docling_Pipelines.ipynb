{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docling Pipelines: All use-cases + LLM Enrichment + Toggles\n",
    "\n",
    "This notebook lets you:\n",
    "- Run all scripts in `scripts/` (with short descriptions).\n",
    "- Toggle Formula Understanding and Picture Description before conversion.\n",
    "- Select LLM provider via env (gemini or gpt) and enrich chunks with structured outputs.\n",
    "\n",
    "Inputs go in `source/`. Outputs are written to `output/`."
   ],
   "id": "4fd2a6694ba3bbf6"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T13:19:26.300796Z",
     "start_time": "2025-08-19T13:19:24.471850Z"
    }
   },
   "source": [
    "# Install dependencies (safe to re-run)\n",
    "!pip install -q -r requirements.txt"
   ],
   "id": "708c4e28803ad107",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T14:01:58.869904Z",
     "start_time": "2025-08-19T14:01:58.859092Z"
    }
   },
   "source": "# Load environment and configure provider\nimport os\nfrom pathlib import Path\nfrom dotenv import load_dotenv\n\n# Ensure CUDA is visible\nos.environ['CUDA_VISIBLE_DEVICES'] = '0'\n\n# Load .env if present. You can copy env.example to .env and fill keys.\nif Path('.env').exists():\n    load_dotenv('.env')\nelse:\n    load_dotenv()  # load from environment only\n\n# Provider: 'gemini' or 'gpt' (from env PROVIDER)\nPROVIDER = os.getenv('PROVIDER', 'gemini').strip().lower()\nOPENAI_MODEL = os.getenv('OPENAI_MODEL', 'gpt-4o-mini')\nGEMINI_MODEL = os.getenv('GEMINI_MODEL', 'gemini-2.5-flash')\n\nprint('Provider:', PROVIDER)\nprint('OPENAI_MODEL:', OPENAI_MODEL)\nprint('GEMINI_MODEL:', GEMINI_MODEL)",
   "id": "71b4dd6db1a8fa4f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provider: gemini\n",
      "OPENAI_MODEL: gpt-4o-mini\n",
      "GEMINI_MODEL: gemini-2.5-flash\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T14:02:00.955916Z",
     "start_time": "2025-08-19T14:02:00.951437Z"
    }
   },
   "source": [
    "# Paths\n",
    "project_root = Path().resolve()\n",
    "src_dir = project_root / 'source'\n",
    "out_dir = project_root / 'output'\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "print('Project root:', project_root)\n",
    "print('Source dir:', src_dir)\n",
    "print('Output dir:', out_dir)\n",
    "print('Source files:', list(src_dir.glob('*')))"
   ],
   "id": "e947cec027435afe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: D:\\GIT\\docling-pipelines\n",
      "Source dir: D:\\GIT\\docling-pipelines\\source\n",
      "Output dir: D:\\GIT\\docling-pipelines\\output\n",
      "Source files: [WindowsPath('D:/GIT/docling-pipelines/source/.gitkeep'), WindowsPath('D:/GIT/docling-pipelines/source/A Level Mathematics_ Mechanics Coursebook.pdf'), WindowsPath('D:/GIT/docling-pipelines/source/AS & A Level Mathematics_ Probability & Statistics 1 Coursebook (2018).pdf'), WindowsPath('D:/GIT/docling-pipelines/source/AS and A Level Mathematics_ Mechanics Coursebook (2018).pdf'), WindowsPath('D:/GIT/docling-pipelines/source/AS _ A Level Mathematics_ Pure Mathematics 1 Coursebook (2018).pdf'), WindowsPath('D:/GIT/docling-pipelines/source/AS _ A Level Mathematics_ Pure Mathematics 2 _ 3 Coursebook (2018).pdf')]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "0o3sbt85z5h",
   "source": "# Verify CUDA setup\nimport torch\nprint(f'PyTorch version: {torch.__version__}')\nprint(f'CUDA available: {torch.cuda.is_available()}')\nif torch.cuda.is_available():\n    print(f'CUDA version: {torch.version.cuda}')\n    print(f'GPU: {torch.cuda.get_device_name(0)}')\n    print(f'GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB')\n    # Test tensor on GPU\n    test_tensor = torch.ones(2, 2).cuda()\n    print(f'Test tensor created on: {test_tensor.device}')\nelse:\n    print('⚠️ CUDA not available - Docling will use CPU')",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T14:02:06.258178Z",
     "start_time": "2025-08-19T14:02:04.191878Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "CUDA version: 12.1\n",
      "GPU: NVIDIA GeForce RTX 4070 Laptop GPU\n",
      "GPU Memory: 8.00 GB\n",
      "Test tensor created on: cuda:0\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Scripts quick-run (what each does)"
   ],
   "id": "d0e8e3106e50fddb"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `general_convert.py`: basic PDF/URL conversion to Markdown/JSON."
   ],
   "id": "8f7567c6144ebee8"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%run scripts/general_convert.py"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "5f888e70adfa86c7"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `vlm_image_understanding.py`: VLM (SmolDocling) for image-heavy PDFs."
   ],
   "id": "e1e5b20abe5ce1cc"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%run scripts/vlm_image_understanding.py"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "4ca8a767ab6374d9"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `maths_processing.py`: converts and extracts math snippets heuristically."
   ],
   "id": "2f672e6feba7e6b2"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%run scripts/maths_processing.py"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "775c92c1957a2e56"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `contextual_hybrid_chunking.py`: HybridChunker raw + contextualized chunks."
   ],
   "id": "c318110daad0130e"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%run scripts/contextual_hybrid_chunking.py"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "3a15d6360df3b370"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `enrich_formula_understanding.py`: Formula Understanding enrichment (LaTeX/MathML)."
   ],
   "id": "3ec35f935b691a68"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%run scripts/enrich_formula_understanding.py"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "85c63806ca2256c"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `enrich_picture_description.py`: Picture Description enrichment (VLM captions)."
   ],
   "id": "e8c1a4954cac5703"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%run scripts/enrich_picture_description.py"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "77bc7114f3e66652"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) One-pass combination: picture description + formula enrichment + contextual chunkings + LLM enrichment options\n",
    "- Toggle Formula/Picture in the cell below.\n",
    "- Select provider via PROVIDER in .env (gemini/gpt).\n",
    "- Produces TXT/JSONL of enriched chunks (structured)."
   ],
   "id": "7424f9f38dadf87f"
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-08-19T14:02:11.912093Z"
    }
   },
   "source": "# Toggles (set True/False or override via env if you prefer)\nDO_FORMULA = True   # <- set False to disable Formula Understanding\nDO_PICTURE = False   # <- set False to disable Picture Description\nDO_LLM = False       # <- set False to disable LLM enrichment\n\nprint('DO_FORMULA:', DO_FORMULA, '| DO_PICTURE:', DO_PICTURE, '| DO_LLM:', DO_LLM)\n\n# Check CUDA availability and set device\nimport torch\nif torch.cuda.is_available():\n    device = 'cuda'\n    print(f'CUDA is available! Using GPU: {torch.cuda.get_device_name(0)}')\n    print(f'CUDA version: {torch.version.cuda}')\n    # Set CUDA device for PyTorch\n    torch.cuda.set_device(0)\nelse:\n    device = 'cpu'\n    print('CUDA not available, using CPU')\n\nfrom datetime import datetime\nfrom docling.document_converter import DocumentConverter, PdfFormatOption\nfrom docling.datamodel.pipeline_options import PdfPipelineOptions\nfrom docling.datamodel.base_models import InputFormat\nfrom docling.chunking import HybridChunker\n\n# Configure Docling pipeline based on toggles\npdf_opts = PdfPipelineOptions()\npdf_opts.do_formula_enrichment = bool(DO_FORMULA)\npdf_opts.do_picture_description = bool(DO_PICTURE)\n# Tip: you could choose a picture description preset here if desired\n# from docling.datamodel.pipeline_options import smolvlm_picture_description\n# pdf_opts.picture_description_options = smolvlm_picture_description\n\nconverter = DocumentConverter(\n    format_options={InputFormat.PDF: PdfFormatOption(pipeline_options=pdf_opts)}\n)\n\n# Pick a PDF\npdf_path = next((p for p in src_dir.glob('*.pdf')), None)\nassert pdf_path is not None, 'Put a PDF into source/'\n\ndl_doc = converter.convert(str(pdf_path)).document\n\n# Chunk\nchunker = HybridChunker()\nchunks = list(chunker.chunk(dl_doc=dl_doc))\n\n# LLM enrichment (conditional on DO_LLM)\nif DO_LLM:\n    # Create selected LLM client\n    if PROVIDER == 'gpt':\n        from clients.openai_client import OpenAIClient, EnrichedChunk\n        llm = OpenAIClient(model=OPENAI_MODEL)\n    elif PROVIDER == 'gemini':\n        from clients.gemini_client import GeminiClient, EnrichedChunk\n        llm = GeminiClient(model=GEMINI_MODEL)\n    else:\n        raise ValueError(f'Unsupported PROVIDER: {PROVIDER}')\n\n# Write outputs\nts = datetime.now().strftime('%Y%m%d_%H%M%S')\nbase = f'{pdf_path.stem}__combo_llm__{PROVIDER}__{ts}' if DO_LLM else f'{pdf_path.stem}__combo_basic__{ts}'\ntxt_path = out_dir / f'{base}.txt'\njsonl_path = out_dir / f'{base}.jsonl'\n\nimport json\nwith txt_path.open('w', encoding='utf-8') as f_txt, jsonl_path.open('w', encoding='utf-8') as f_jsonl:\n    for i, ch in enumerate(chunks):\n        raw = ch.text or ''\n        structural = chunker.contextualize(chunk=ch)\n        \n        if DO_LLM:\n            enriched = llm.enrich_chunk(raw, context=structural)  # Pydantic validated\n            # TXT with LLM enrichment\n            f_txt.write(f'=== {i} ===\\n')\n            f_txt.write('-- title --\\n' + (enriched.title or '') + '\\n')\n            f_txt.write('-- summary --\\n' + enriched.summary + '\\n')\n            f_txt.write('-- key_points --\\n' + '\\n'.join('- ' + kp for kp in enriched.key_points) + '\\n')\n            f_txt.write('-- enriched_text --\\n' + enriched.enriched_text + '\\n\\n')\n            # JSONL with LLM enrichment\n            f_jsonl.write(json.dumps({\n                'index': i,\n                'title': enriched.title,\n                'summary': enriched.summary,\n                'key_points': enriched.key_points,\n                'enriched_text': enriched.enriched_text,\n                'path': getattr(ch, 'path', None),\n                'id': getattr(ch, 'id', None),\n            }, ensure_ascii=False) + '\\n')\n        else:\n            # Basic output without LLM enrichment\n            f_txt.write(f'=== {i} ===\\n')\n            f_txt.write('-- raw_text --\\n' + raw + '\\n')\n            f_txt.write('-- structural_context --\\n' + structural + '\\n\\n')\n            # JSONL without LLM enrichment\n            f_jsonl.write(json.dumps({\n                'index': i,\n                'raw_text': raw,\n                'structural_context': structural,\n                'path': getattr(ch, 'path', None),\n                'id': getattr(ch, 'id', None),\n            }, ensure_ascii=False) + '\\n')\n\nprint('Wrote:', txt_path)\nprint('Wrote:', jsonl_path)",
   "id": "bd36358565daed80",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DO_FORMULA: True | DO_PICTURE: False | DO_LLM: False\n",
      "CUDA is available! Using GPU: NVIDIA GeForce RTX 4070 Laptop GPU\n",
      "CUDA version: 12.1\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Inspect outputs"
   ],
   "id": "58979a6e4442da8"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "for p in sorted(out_dir.glob('*')):\n",
    "    print(p.name)"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "379750bdf53fb38b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
