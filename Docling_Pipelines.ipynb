{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Docling Pipelines: All use-cases + LLM Enrichment + Toggles\n",
    "\n",
    "This notebook lets you:\n",
    "- Run all scripts in `scripts/` (with short descriptions).\n",
    "- Toggle Formula Understanding and Picture Description before conversion.\n",
    "- Select LLM provider via env (gemini or gpt) and enrich chunks with structured outputs.\n",
    "\n",
    "Inputs go in `source/`. Outputs are written to `output/`."
   ],
   "id": "4fd2a6694ba3bbf6"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T14:07:28.902319Z",
     "start_time": "2025-08-19T14:07:26.912385Z"
    }
   },
   "source": [
    "import logging\n",
    "# Install dependencies (safe to re-run)\n",
    "!pip install -q -r requirements.txt"
   ],
   "id": "708c4e28803ad107",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T14:07:38.201554Z",
     "start_time": "2025-08-19T14:07:38.195523Z"
    }
   },
   "source": [
    "# Load environment and configure provider\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Ensure CUDA is visible\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "# Load .env if present. You can copy env.example to .env and fill keys.\n",
    "if Path('.env').exists():\n",
    "    load_dotenv('.env')\n",
    "else:\n",
    "    load_dotenv()  # load from environment only\n",
    "\n",
    "# Provider: 'gemini' or 'gpt' (from env PROVIDER)\n",
    "PROVIDER = os.getenv('PROVIDER', 'gemini').strip().lower()\n",
    "OPENAI_MODEL = os.getenv('OPENAI_MODEL', 'gpt-4o-mini')\n",
    "GEMINI_MODEL = os.getenv('GEMINI_MODEL', 'gemini-2.5-flash')\n",
    "\n",
    "print('Provider:', PROVIDER)\n",
    "print('OPENAI_MODEL:', OPENAI_MODEL)\n",
    "print('GEMINI_MODEL:', GEMINI_MODEL)\n",
    "\n",
    "# Configure logging for your script\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "log = logging.getLogger(__name__)  # This makes your script a logging-aware application"
   ],
   "id": "71b4dd6db1a8fa4f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Provider: gemini\n",
      "OPENAI_MODEL: gpt-4o-mini\n",
      "GEMINI_MODEL: gemini-2.5-flash\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T14:07:42.512254Z",
     "start_time": "2025-08-19T14:07:42.507491Z"
    }
   },
   "source": [
    "# Paths\n",
    "project_root = Path().resolve()\n",
    "src_dir = project_root / 'source'\n",
    "out_dir = project_root / 'output'\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "print('Project root:', project_root)\n",
    "print('Source dir:', src_dir)\n",
    "print('Output dir:', out_dir)\n",
    "print('Source files:', list(src_dir.glob('*')))"
   ],
   "id": "e947cec027435afe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: D:\\GIT\\docling-pipelines\n",
      "Source dir: D:\\GIT\\docling-pipelines\\source\n",
      "Output dir: D:\\GIT\\docling-pipelines\\output\n",
      "Source files: [WindowsPath('D:/GIT/docling-pipelines/source/.gitkeep'), WindowsPath('D:/GIT/docling-pipelines/source/A Level Mathematics_ Mechanics Coursebook.pdf'), WindowsPath('D:/GIT/docling-pipelines/source/AS & A Level Mathematics_ Probability & Statistics 1 Coursebook (2018).pdf'), WindowsPath('D:/GIT/docling-pipelines/source/AS and A Level Mathematics_ Mechanics Coursebook (2018).pdf'), WindowsPath('D:/GIT/docling-pipelines/source/AS _ A Level Mathematics_ Pure Mathematics 1 Coursebook (2018).pdf'), WindowsPath('D:/GIT/docling-pipelines/source/AS _ A Level Mathematics_ Pure Mathematics 2 _ 3 Coursebook (2018).pdf')]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "0o3sbt85z5h",
   "source": "# Verify CUDA setup\nimport torch\nprint(f'PyTorch version: {torch.__version__}')\nprint(f'CUDA available: {torch.cuda.is_available()}')\nif torch.cuda.is_available():\n    print(f'CUDA version: {torch.version.cuda}')\n    print(f'GPU: {torch.cuda.get_device_name(0)}')\n    print(f'GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB')\n    # Test tensor on GPU\n    test_tensor = torch.ones(2, 2).cuda()\n    print(f'Test tensor created on: {test_tensor.device}')\nelse:\n    print('⚠️ CUDA not available - Docling will use CPU')",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-19T14:02:06.258178Z",
     "start_time": "2025-08-19T14:02:04.191878Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "CUDA version: 12.1\n",
      "GPU: NVIDIA GeForce RTX 4070 Laptop GPU\n",
      "GPU Memory: 8.00 GB\n",
      "Test tensor created on: cuda:0\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Scripts quick-run (what each does)"
   ],
   "id": "d0e8e3106e50fddb"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `general_convert.py`: basic PDF/URL conversion to Markdown/JSON."
   ],
   "id": "8f7567c6144ebee8"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%run scripts/general_convert.py"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "5f888e70adfa86c7"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `vlm_image_understanding.py`: VLM (SmolDocling) for image-heavy PDFs."
   ],
   "id": "e1e5b20abe5ce1cc"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%run scripts/vlm_image_understanding.py"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "4ca8a767ab6374d9"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `maths_processing.py`: converts and extracts math snippets heuristically."
   ],
   "id": "2f672e6feba7e6b2"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%run scripts/maths_processing.py"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "775c92c1957a2e56"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `contextual_hybrid_chunking.py`: HybridChunker raw + contextualized chunks."
   ],
   "id": "c318110daad0130e"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%run scripts/contextual_hybrid_chunking.py"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "3a15d6360df3b370"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `enrich_formula_understanding.py`: Formula Understanding enrichment (LaTeX/MathML)."
   ],
   "id": "3ec35f935b691a68"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%run scripts/enrich_formula_understanding.py"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "85c63806ca2256c"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `enrich_picture_description.py`: Picture Description enrichment (VLM captions)."
   ],
   "id": "e8c1a4954cac5703"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%run scripts/enrich_picture_description.py"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "77bc7114f3e66652"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) One-pass combination: picture description + formula enrichment + contextual chunkings + LLM enrichment options\n",
    "- Toggle Formula/Picture in the cell below.\n",
    "- Select provider via PROVIDER in .env (gemini/gpt).\n",
    "- Produces TXT/JSONL of enriched chunks (structured)."
   ],
   "id": "7424f9f38dadf87f"
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-08-19T14:09:30.640799Z"
    }
   },
   "source": [
    "# Toggles (set True/False or override via env if you prefer)\n",
    "DO_FORMULA = True   # <- set False to disable Formula Understanding\n",
    "DO_PICTURE = False   # <- set False to disable Picture Description\n",
    "DO_LLM = False       # <- set False to disable LLM enrichment\n",
    "\n",
    "print('DO_FORMULA:', DO_FORMULA, '| DO_PICTURE:', DO_PICTURE, '| DO_LLM:', DO_LLM)\n",
    "\n",
    "# Check CUDA availability and set device\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "    print(f'CUDA is available! Using GPU: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'CUDA version: {torch.version.cuda}')\n",
    "    # Set CUDA device for PyTorch\n",
    "    torch.cuda.set_device(0)\n",
    "else:\n",
    "    device = 'cpu'\n",
    "    print('CUDA not available, using CPU')\n",
    "\n",
    "from datetime import datetime\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.chunking import HybridChunker\n",
    "\n",
    "# Configure Docling pipeline based on toggles\n",
    "pdf_opts = PdfPipelineOptions()\n",
    "pdf_opts.do_formula_enrichment = bool(DO_FORMULA)\n",
    "pdf_opts.do_picture_description = bool(DO_PICTURE)\n",
    "# Tip: you could choose a picture description preset here if desired\n",
    "# from docling.datamodel.pipeline_options import smolvlm_picture_description\n",
    "# pdf_opts.picture_description_options = smolvlm_picture_description\n",
    "\n",
    "converter = DocumentConverter(\n",
    "    format_options={InputFormat.PDF: PdfFormatOption(pipeline_options=pdf_opts)}\n",
    ")\n",
    "\n",
    "# Pick a PDF\n",
    "pdf_path = next((p for p in src_dir.glob('*.pdf')), None)\n",
    "assert pdf_path is not None, 'Put a PDF into source/'\n",
    "print('Using PDF:', pdf_path)\n",
    "\n",
    "dl_doc = converter.convert(str(pdf_path)).document\n",
    "\n",
    "# Chunk\n",
    "chunker = HybridChunker()\n",
    "chunks = list(chunker.chunk(dl_doc=dl_doc))\n",
    "\n",
    "# LLM enrichment (conditional on DO_LLM)\n",
    "if DO_LLM:\n",
    "    # Create selected LLM client\n",
    "    if PROVIDER == 'gpt':\n",
    "        from clients.openai_client import OpenAIClient, EnrichedChunk\n",
    "        llm = OpenAIClient(model=OPENAI_MODEL)\n",
    "    elif PROVIDER == 'gemini':\n",
    "        from clients.gemini_client import GeminiClient, EnrichedChunk\n",
    "        llm = GeminiClient(model=GEMINI_MODEL)\n",
    "    else:\n",
    "        raise ValueError(f'Unsupported PROVIDER: {PROVIDER}')\n",
    "\n",
    "# Write outputs\n",
    "ts = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "base = f'{pdf_path.stem}__combo_llm__{PROVIDER}__{ts}' if DO_LLM else f'{pdf_path.stem}__combo_basic__{ts}'\n",
    "txt_path = out_dir / f'{base}.txt'\n",
    "jsonl_path = out_dir / f'{base}.jsonl'\n",
    "\n",
    "import json\n",
    "with txt_path.open('w', encoding='utf-8') as f_txt, jsonl_path.open('w', encoding='utf-8') as f_jsonl:\n",
    "    for i, ch in enumerate(chunks):\n",
    "        raw = ch.text or ''\n",
    "        structural = chunker.contextualize(chunk=ch)\n",
    "        \n",
    "        if DO_LLM:\n",
    "            enriched = llm.enrich_chunk(raw, context=structural)  # Pydantic validated\n",
    "            # TXT with LLM enrichment\n",
    "            f_txt.write(f'=== {i} ===\\n')\n",
    "            f_txt.write('-- title --\\n' + (enriched.title or '') + '\\n')\n",
    "            f_txt.write('-- summary --\\n' + enriched.summary + '\\n')\n",
    "            f_txt.write('-- key_points --\\n' + '\\n'.join('- ' + kp for kp in enriched.key_points) + '\\n')\n",
    "            f_txt.write('-- enriched_text --\\n' + enriched.enriched_text + '\\n\\n')\n",
    "            # JSONL with LLM enrichment\n",
    "            f_jsonl.write(json.dumps({\n",
    "                'index': i,\n",
    "                'title': enriched.title,\n",
    "                'summary': enriched.summary,\n",
    "                'key_points': enriched.key_points,\n",
    "                'enriched_text': enriched.enriched_text,\n",
    "                'path': getattr(ch, 'path', None),\n",
    "                'id': getattr(ch, 'id', None),\n",
    "            }, ensure_ascii=False) + '\\n')\n",
    "        else:\n",
    "            # Basic output without LLM enrichment\n",
    "            f_txt.write(f'=== {i} ===\\n')\n",
    "            f_txt.write('-- raw_text --\\n' + raw + '\\n')\n",
    "            f_txt.write('-- structural_context --\\n' + structural + '\\n\\n')\n",
    "            # JSONL without LLM enrichment\n",
    "            f_jsonl.write(json.dumps({\n",
    "                'index': i,\n",
    "                'raw_text': raw,\n",
    "                'structural_context': structural,\n",
    "                'path': getattr(ch, 'path', None),\n",
    "                'id': getattr(ch, 'id', None),\n",
    "            }, ensure_ascii=False) + '\\n')\n",
    "\n",
    "print('Wrote:', txt_path)\n",
    "print('Wrote:', jsonl_path)"
   ],
   "id": "bd36358565daed80",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:docling.datamodel.document:detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "INFO:docling.document_converter:Going to convert document batch...\n",
      "INFO:docling.document_converter:Initializing pipeline for StandardPdfPipeline with options hash 668406b0360ad5b5edcd6e26ef746f05\n",
      "INFO:docling.utils.accelerator_utils:Accelerator device: 'cuda:0'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DO_FORMULA: True | DO_PICTURE: False | DO_LLM: False\n",
      "CUDA is available! Using GPU: NVIDIA GeForce RTX 4070 Laptop GPU\n",
      "CUDA version: 12.1\n",
      "Using PDF: D:\\GIT\\docling-pipelines\\source\\A Level Mathematics_ Mechanics Coursebook.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:docling.utils.accelerator_utils:Accelerator device: 'cuda:0'\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /api/models/ds4sd/docling-layout-old/revision/main HTTP/1.1\" 200 797\n",
      "DEBUG:docling_ibm_models.layoutmodel.layout_predictor:LayoutPredictor settings: {'model_name': 'RTDetrForObjectDetection', 'safe_tensors_file': 'C:\\\\Users\\\\roshan.summun\\\\.cache\\\\huggingface\\\\hub\\\\models--ds4sd--docling-layout-old\\\\snapshots\\\\b5b4bd59ad2b69aab715e9b1f1dfd74394c45fd4\\\\model.safetensors', 'device': 'cuda', 'num_threads': 4, 'image_size': {'height': 640, 'width': 640}, 'threshold': 0.3}\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /api/models/ds4sd/docling-models/revision/v2.2.0 HTTP/1.1\" 200 1266\n",
      "INFO:docling.utils.accelerator_utils:Accelerator device: 'cuda:0'\n",
      "INFO:docling.utils.accelerator_utils:Accelerator device: 'cuda:0'\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /api/models/ds4sd/CodeFormula/revision/v1.0.2 HTTP/1.1\" 200 1195\n",
      "DEBUG:docling_ibm_models.code_formula_model.code_formula_predictor:CodeFormulaModel settings: {'device': 'cuda:0', 'num_threads': 4}\n",
      "INFO:docling.pipeline.base_pipeline:Processing document A Level Mathematics_ Mechanics Coursebook.pdf\n",
      "DEBUG:docling.pipeline.base_pipeline:Finished converting page batch time=1234505.703\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Inspect outputs"
   ],
   "id": "58979a6e4442da8"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "for p in sorted(out_dir.glob('*')):\n",
    "    print(p.name)"
   ],
   "execution_count": null,
   "outputs": [],
   "id": "379750bdf53fb38b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
